{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Arabic Motivational Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "DbL_CaZQFpkG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AHjBgTIZAxdh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from string import punctuation\n",
        "import string \n",
        "import re\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Data**"
      ],
      "metadata": {
        "id": "pdVADXO5GQau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for colab\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaHpTpwWGRqs",
        "outputId": "a5046de1-4c93-47f6-e7a3-729094d905c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for colab\n",
        "!unzip '/content/drive/MyDrive/Colab Notebooks/arabic qoutes.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6BEB9m1IbrY",
        "outputId": "875cf143-5411-463d-8c52-aa790e52684b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab Notebooks/arabic qoutes.zip\n",
            "   creating: arabic qoutes/\n",
            "  inflating: arabic qoutes/arabic qoutes.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_Text = open('arabic qoutes/arabic qoutes.txt','rb').read().decode(encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "xPmz9VXCIg4u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Exploration and Preprocessing**"
      ],
      "metadata": {
        "id": "4TDE46iqJG1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(format(len(Motivational_Text))) # length of charcaters in text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvsMglsHJIOx",
        "outputId": "cc7317f5-1d0c-488a-877a-ce5d46d6f52e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Motivational_Text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwHXc-XIKBK8",
        "outputId": "228b1e52-8538-45d6-9461-e2b8bf3b6773"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "عليك أن تتعلم قواعد اللعبة ثم عليك أن تلعب أفضل من أي شخص آخر\r\n",
            "مع كل شيءٍ تفقده تكتسب شيئًا آخر. لذلك تذوّق قيمة ما لديك اليوم؛ فالحياة ليس من الضروري أن تبدو مثالية في عينيك حتى تستشعر قيمة وروعة ما لديك. \r\n",
            "تكون السُفُن آمِنة عندما تكون راسية على ال\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_vocab =sorted(set(Motivational_Text))\n",
        "print(\"unique_chars:\", Motivational_vocab)\n",
        "n_unique_chars = len(Motivational_vocab) \n",
        "print(\"Number of unique characters:\", n_unique_chars) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B77IM-fKEn-",
        "outputId": "e15708ed-5afc-460d-ad4f-55b2165cf447"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_chars: ['\\n', '\\r', ' ', '!', '\"', '%', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', ':', '>', '،', '؛', '؟', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ـ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', '٪', 'ٰ', '\\u200b', '\\u200c', '\\u200f', '–', '“', '”', '…']\n",
            "Number of unique characters: 77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**"
      ],
      "metadata": {
        "id": "XqHs3WzIKVY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Remove Punctuation:**"
      ],
      "metadata": {
        "id": "QkMItZmiL_Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ArabicPunctuations= '''`÷×؛<>_()*&^%][-ـ/\",'{}~¦+|”…“–ـ'''\n",
        "EnglishPunctuations = string.punctuation\n",
        "punctuations_list = ArabicPunctuations + EnglishPunctuations\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QZ5J3J1mKohf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Motivational_Text:\n",
        "      \n",
        "    # checking whether the char is punctuation.\n",
        "    if i in ArabicPunctuations:\n",
        "          \n",
        "        # Printing the punctuation values \n",
        "        print(\"Punctuation: \" + i)\n",
        "   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcaAKS5WOkC4",
        "outputId": "678634f4-8a01-4734-d0bf-d5b6f3a5b069"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation: ؛\n",
            "Punctuation: ”\n",
            "Punctuation: …\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ؛\n",
            "Punctuation: “\n",
            "Punctuation: ”\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ـ\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: –\n",
            "Punctuation: ؛\n",
            "Punctuation: …\n",
            "Punctuation: –\n",
            "Punctuation: –\n",
            "Punctuation: ”\n",
            "Punctuation: ”\n",
            "Punctuation: –\n",
            "Punctuation: –\n",
            "Punctuation: '\n",
            "Punctuation: '\n",
            "Punctuation: ـ\n",
            "Punctuation: (\n",
            "Punctuation: )\n",
            "Punctuation: >\n",
            "Punctuation: %\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: \"\n",
            "Punctuation: \"\n",
            "Punctuation: ,\n",
            "Punctuation: ؛\n",
            "Punctuation: /\n",
            "Punctuation: ؛\n",
            "Punctuation: ـ\n",
            "Punctuation: ؛\n",
            "Punctuation: ؛\n",
            "Punctuation: ؛\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: ؛\n",
            "Punctuation: ؛\n",
            "Punctuation: -\n",
            "Punctuation: ؛\n",
            "Punctuation: ؛\n",
            "Punctuation: ؛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Motivational_Text:\n",
        "      \n",
        "    # checking whether the char is punctuation.\n",
        "    if i in EnglishPunctuations:\n",
        "          \n",
        "        # Printing the punctuation values \n",
        "        print(\"Punctuation: \" + i)\n",
        "   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ8QdB_jPrag",
        "outputId": "63f78708-e3dc-4a2a-e02c-03a5a7ef3267"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: -\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: !\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: '\n",
            "Punctuation: '\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: (\n",
            "Punctuation: )\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: >\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: %\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: \"\n",
            "Punctuation: \"\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: ,\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: /\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: !\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: -\n",
            "Punctuation: .\n",
            "Punctuation: -\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: -\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: -\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: :\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: -\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n",
            "Punctuation: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_Text = Motivational_Text.translate(str.maketrans(\"\", \"\", punctuations_list))"
      ],
      "metadata": {
        "id": "CnDRCMMtOWXl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_vocab =sorted(set(Motivational_Text))\n",
        "print(\"unique_chars:\", Motivational_vocab)\n",
        "n_unique_chars = len(Motivational_vocab) \n",
        "print(\"Number of unique characters:\", n_unique_chars) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NE7wvdoPJaG",
        "outputId": "85894001-3758-4740-8e60-7d1f7a93949e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_chars: ['\\n', '\\r', ' ', '0', '1', '2', '3', '4', '،', '؟', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', '٪', 'ٰ', '\\u200b', '\\u200c', '\\u200f']\n",
            "Number of unique characters: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Remove Arabic Diacritics**"
      ],
      "metadata": {
        "id": "2MFduqk5O9_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arabicDiacritics = re.compile(\"\"\"\n",
        "                             ّ    | # Tashdid\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "\n",
        "                         \"\"\", re.VERBOSE)"
      ],
      "metadata": {
        "id": "eC6Dj8vsO8_2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_Text = re.sub(arabicDiacritics, '', Motivational_Text)\n"
      ],
      "metadata": {
        "id": "MNmH2EyENyV2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_vocab =sorted(set(Motivational_Text))\n",
        "print(\"unique_chars:\", Motivational_vocab)\n",
        "n_unique_chars = len(Motivational_vocab) \n",
        "print(\"Number of unique characters:\", n_unique_chars) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbdydf8CQoVs",
        "outputId": "f1b10f4a-e9de-4caa-81f4-ad6e6c216a39"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_chars: ['\\n', '\\r', ' ', '0', '1', '2', '3', '4', '،', '؟', 'ء', 'آ', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', '٪', 'ٰ', '\\u200b', '\\u200c', '\\u200f']\n",
            "Number of unique characters: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Normalize arabic**"
      ],
      "metadata": {
        "id": "bVhmEHrKR2yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_Text = re.sub(\"[إأآا]\", \"ا\", Motivational_Text)\n",
        "Motivational_Text = re.sub(\"ى\", \"ي\", Motivational_Text)\n",
        "Motivational_Text = re.sub(\"ؤ\", \"ء\", Motivational_Text)\n",
        "Motivational_Text = re.sub(\"ئ\", \"ء\", Motivational_Text)\n",
        "Motivational_Text = re.sub(\"ة\", \"ه\", Motivational_Text)\n",
        "Motivational_Text = re.sub(\"گ\", \"ك\", Motivational_Text)\n",
        "\n"
      ],
      "metadata": {
        "id": "gObABMSXNuv4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_vocab =sorted(set(Motivational_Text))\n",
        "print(\"unique_chars:\", Motivational_vocab)\n",
        "n_unique_chars = len(Motivational_vocab) \n",
        "print(\"Number of unique characters:\", n_unique_chars) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8HTPZZTR-gF",
        "outputId": "d74dcd90-1ab0-46ab-d148-7c703a40a388"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_chars: ['\\n', '\\r', ' ', '0', '1', '2', '3', '4', '،', '؟', 'ء', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', '٪', 'ٰ', '\\u200b', '\\u200c', '\\u200f']\n",
            "Number of unique characters: 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_Text = re.sub('\\u200c', \"\", Motivational_Text)\n",
        "Motivational_Text = re.sub('\\u200b', \"\", Motivational_Text)\n",
        "Motivational_Text = re.sub('\\u200f', \"\", Motivational_Text)\n"
      ],
      "metadata": {
        "id": "UZicVDw3N7OQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Motivational_vocab =sorted(set(Motivational_Text))\n",
        "print(\"unique_chars:\", Motivational_vocab)\n",
        "n_unique_chars = len(Motivational_vocab) \n",
        "print(\"Number of unique characters:\", n_unique_chars) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9KAcfV6SvUA",
        "outputId": "4573f7c6-cfe2-44c5-ba60-45c56227d560"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_chars: ['\\n', '\\r', ' ', '0', '1', '2', '3', '4', '،', '؟', 'ء', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', '٪', 'ٰ']\n",
            "Number of unique characters: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(format(len(Motivational_Text))) # length of charcaters in text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4dp6uS6N4xl",
        "outputId": "4fa66977-41c1-4bfe-ef8b-adb036c5e270"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Change from character to integer**"
      ],
      "metadata": {
        "id": "dxvcEdydmRFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(Motivational_Text)))\n"
      ],
      "metadata": {
        "id": "QXU6oIQamSK7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0hPRiIvmpRo",
        "outputId": "bcf98bab-a09b-4cc9-94a8-413e71526687"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars[:15]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MMcKoVtmrJT",
        "outputId": "b45bdae8-bdb7-43e5-d973-9a6d46229bbc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n', '\\r', ' ', '0', '1', '2', '3', '4', '،', '؟', 'ء', 'ا', 'ب', 'ت', 'ث']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num = dict((c, i) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "_W2C9UCkmrM1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_num\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhPGOFGVmrQa",
        "outputId": "3157cdef-5046-423d-a05c-7d8171db1716"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " '\\r': 1,\n",
              " ' ': 2,\n",
              " '0': 3,\n",
              " '1': 4,\n",
              " '2': 5,\n",
              " '3': 6,\n",
              " '4': 7,\n",
              " '،': 8,\n",
              " '؟': 9,\n",
              " 'ء': 10,\n",
              " 'ا': 11,\n",
              " 'ب': 12,\n",
              " 'ت': 13,\n",
              " 'ث': 14,\n",
              " 'ج': 15,\n",
              " 'ح': 16,\n",
              " 'خ': 17,\n",
              " 'د': 18,\n",
              " 'ذ': 19,\n",
              " 'ر': 20,\n",
              " 'ز': 21,\n",
              " 'س': 22,\n",
              " 'ش': 23,\n",
              " 'ص': 24,\n",
              " 'ض': 25,\n",
              " 'ط': 26,\n",
              " 'ظ': 27,\n",
              " 'ع': 28,\n",
              " 'غ': 29,\n",
              " 'ف': 30,\n",
              " 'ق': 31,\n",
              " 'ك': 32,\n",
              " 'ل': 33,\n",
              " 'م': 34,\n",
              " 'ن': 35,\n",
              " 'ه': 36,\n",
              " 'و': 37,\n",
              " 'ي': 38,\n",
              " '٪': 39,\n",
              " 'ٰ': 40}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_len = len(Motivational_Text)\n",
        "vocab_len = len(chars)\n",
        "print (\"Total number of characters:\", input_len)\n",
        "print (\"Total vocab:\", vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nopzZtD0myO3",
        "outputId": "06fbaac2-e345-4729-9b7e-5f7289f3b3e3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 29363\n",
            "Total vocab: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data** "
      ],
      "metadata": {
        "id": "wP1rUZk0m47B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "O3lmTQhcm7HV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through inputs, start at the beginning and go until we hit\n",
        "# the final character we can create a sequence out of\n",
        "for i in range(0, input_len - seq_length, 1):\n",
        "    # Define input and output sequences\n",
        "    # Input is the current character plus desired sequence length\n",
        "    in_seq = Motivational_Text[i:i + seq_length]\n",
        "\n",
        "    # Out sequence is the initial character plus total sequence length\n",
        "    out_seq = Motivational_Text[i + seq_length]\n",
        "\n",
        "    # We now convert list of characters to integers based on\n",
        "    # previously and add the values to our lists\n",
        "    x_data.append([char_to_num[char] for char in in_seq])\n",
        "    y_data.append(char_to_num[out_seq])"
      ],
      "metadata": {
        "id": "bafW0ljRm77h"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = len(x_data)\n",
        "print (\"Total Patterns:\", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASXZrPrzm8BX",
        "outputId": "aa25baca-49f7-4600-affe-8e40557a3b5c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 29263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "metadata": {
        "id": "D4iVk1K7m8F9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np_utils.to_categorical(y_data)\n"
      ],
      "metadata": {
        "id": "5dYizU9JnMkK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "xGm4TExInYz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "id": "P0tJip53na_q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "h_n-N6Lwnosx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X, y, epochs=150, batch_size=256,verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "RXbNoGPQnfz6",
        "outputId": "23197965-9f10-4599-d404-c347cfac8d6b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115/115 [==============================] - 19s 161ms/step - loss: 0.6951 - accuracy: 0.7823\n",
            "Epoch 98/150\n",
            "115/115 [==============================] - 18s 161ms/step - loss: 0.6879 - accuracy: 0.7831\n",
            "Epoch 99/150\n",
            "115/115 [==============================] - 19s 161ms/step - loss: 0.6796 - accuracy: 0.7865\n",
            "Epoch 100/150\n",
            " 47/115 [===========>..................] - ETA: 10s - loss: 0.6573 - accuracy: 0.7896"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-5edc64bbe4ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict "
      ],
      "metadata": {
        "id": "u5D9dwF-nxaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "GA6F_j0cn1Av"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nuFlGhan3QF",
        "outputId": "d6ca4519-e195-4778-ae60-0c02a593188b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:\n",
            "\" لي الهزيمه هي الانتصار  ونستون تشرشل\r\n",
            "لعله من عجاءب الحياه ،انك اذا رفضت كل ما هو دون مستوي القمه ،  \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(vocab_len)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = num_to_char[index]\n",
        "    seq_in = [num_to_char[value] for value in pattern]\n",
        "\n",
        "    sys.stdout.write(result)\n",
        "\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hdk1Jjcn6ZO",
        "outputId": "e1b0c232-e4b9-4dbc-d848-3bce20313f23"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "كن معله بن تلنن عظيما لكي تبدا، لكن عليك ان تبدا لكي تكون عظيما\n",
            "الالم الذي تشعر به اليوم هو القوه التي سوف تشعر بها في الغد فلكل تحد يواجه هناك فرصه للنوو\n",
            "النجاح يولد صعير فريا من الانام من اللحاوله بن الفراح\n",
            "\n",
            "راءما من انت مسءول عنهم كما تحب ان يعاملك من هو مسءول عنك \n",
            "\n",
            "\n",
            "ابقار النجاح لو العالم \n",
            "\n",
            "لا تكن اسهل ما في الحياه و لا تكن اصعب ما فيها بل كن انت الحياه في اسمي معانيها\n",
            "\n",
            "بعض النظر انا المفتا مه العلل ال تحوم ال تكون ما انتر منا يعتطيم ان تفعله تععار اواخرين\n",
            "الالسار الذي تصتفد انه النجاح المهما المجاح مو المحاوله بكثر من مره\n",
            "لاحقين مانا انتر \n",
            "الاستيار تلنجاح في المقول الذي يررلين ان تعون الاخراص\n",
            "الفووس هو ذيك الشءءل لاللءك الذين يرددون مستحيل \n",
            "اذا لم تفشل، فلن تعمل بجد \n",
            "اذا كنت تستطيع تخيل صوره ما، يمكنك ان تجعلها واقعا، واذا كنت تستطيع ا"
          ]
        }
      ]
    }
  ]
}